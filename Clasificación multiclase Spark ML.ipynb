{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clasificación de tipos de flores, con 3 tipos de modelos de clasificación\n",
    "\n",
    "[Dataset](http://scalableml.com/iris-bezdekIris.php)        \n",
    "[Documentación](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:06:13.090932Z",
     "start_time": "2019-08-16T16:06:08.782636Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import regexp_extract,lit,udf,col\n",
    "from pyspark.sql.types import IntegerType\n",
    "# create sparksession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Pysparkexample\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:06:17.083362Z",
     "start_time": "2019-08-16T16:06:13.095512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-----------+\n",
      "|sep_len|sep_wid|pet_len|pet_wid|      label|\n",
      "+-------+-------+-------+-------+-----------+\n",
      "|    5.1|    3.5|    1.4|    0.2|Iris-setosa|\n",
      "|    4.9|    3.0|    1.4|    0.2|Iris-setosa|\n",
      "|    4.7|    3.2|    1.3|    0.2|Iris-setosa|\n",
      "|    4.6|    3.1|    1.5|    0.2|Iris-setosa|\n",
      "|    5.0|    3.6|    1.4|    0.2|Iris-setosa|\n",
      "+-------+-------+-------+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./iris_bezdekIris.csv\", inferSchema=True)\\\n",
    ".toDF(\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\", \"label\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se transforman las 4 columnas de características (*features*) a 1 sola columna con **VectorAssembler**, al cual se le pasan las columnas de *input* y entrega la columna *output* con todos los valores de las columnas entrantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:06:17.596141Z",
     "start_time": "2019-08-16T16:06:17.086436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-----------+-----------------+\n",
      "|sep_len|sep_wid|pet_len|pet_wid|      label|         features|\n",
      "+-------+-------+-------+-------+-----------+-----------------+\n",
      "|    5.1|    3.5|    1.4|    0.2|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|    4.9|    3.0|    1.4|    0.2|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|    4.7|    3.2|    1.3|    0.2|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "+-------+-------+-------+-------+-----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=[\"sep_len\", \"sep_wid\", \"pet_len\", \"pet_wid\"],\\\n",
    "outputCol=\"features\")\n",
    "df_temp = vector_assembler.transform(df)\n",
    "df_temp.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se remueven las columnas innecesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:06:21.804931Z",
     "start_time": "2019-08-16T16:06:21.578481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|      label|         features|\n",
      "+-----------+-----------------+\n",
      "|Iris-setosa|[5.1,3.5,1.4,0.2]|\n",
      "|Iris-setosa|[4.9,3.0,1.4,0.2]|\n",
      "|Iris-setosa|[4.7,3.2,1.3,0.2]|\n",
      "+-----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_temp.drop('sep_len', 'sep_wid', 'pet_len', 'pet_wid')\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se convierte la columna *label* de texto a una numérica con **StringIndexer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:06:24.363801Z",
     "start_time": "2019-08-16T16:06:23.498166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------+\n",
      "|      label|         features|labelIndex|\n",
      "+-----------+-----------------+----------+\n",
      "|Iris-setosa|[5.1,3.5,1.4,0.2]|       0.0|\n",
      "|Iris-setosa|[4.9,3.0,1.4,0.2]|       0.0|\n",
      "|Iris-setosa|[4.7,3.2,1.3,0.2]|       0.0|\n",
      "+-----------+-----------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "l_indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")\n",
    "df = l_indexer.fit(df).transform(df)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los datos preprocesados, se dividen en sets de entrenamiento (*train*) y prueba (*test*). Para luego aplicar distintos modelos de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:06:26.829239Z",
     "start_time": "2019-08-16T16:06:26.797486Z"
    }
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se implementaron 3 algoritmos:\n",
    "- Decision tree classifier\n",
    "- Random forest classifier\n",
    "- Naive Bayes\n",
    "\n",
    "______________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree classifier\n",
    "**DecisionTreeClassifier**(<span style=\"color:green;\">featuresCol='features'</span>, <span style=\"color:green;\">labelCol='label'</span>, predictionCol='prediction', probabilityCol='probability', rawPredictionCol='rawPrediction', maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0, maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity='gini', <span style=\"color:darkolivegreen;\">seed=None</span>)    \n",
    "\n",
    "Se hace **fit** con los datos de **entrenamiento**. Luego las **predicciones** con los datos de **prueba**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:06:30.476504Z",
     "start_time": "2019-08-16T16:06:29.130197Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"labelIndex\", featuresCol=\"features\")\n",
    "model = dt.fit(trainingData)\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:06:31.453186Z",
     "start_time": "2019-08-16T16:06:31.195818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|prediction|labelIndex|\n",
      "+----------+----------+\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"labelIndex\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:07:57.226443Z",
     "start_time": "2019-08-16T16:07:56.226910Z"
    },
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0227273 \n",
      "Test Accuracy = 97.7273 %\n",
      "f1 = 0.977206\n",
      "weightedPrecision = 0.978535\n",
      "weightedRecall = 0.977273\n",
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_ea78cb93e6b0) of depth 5 with 15 nodes\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\\\n",
    "labelCol=\"labelIndex\", predictionCol=\"prediction\",\\\n",
    "metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g \" % (1.0 - accuracy))\n",
    "print(\"Test Accuracy = %g \" % (accuracy*100)+'%')\n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)\n",
    " \n",
    "evaluatorwp = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "wp = evaluatorwp.evaluate(predictions)\n",
    "print(\"weightedPrecision = %g\" % wp)\n",
    " \n",
    "evaluatorwr = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "wr = evaluatorwr.evaluate(predictions)\n",
    "print(\"weightedRecall = %g\" % wr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier\n",
    "\n",
    "**RandomForestClassifier**(<span style=\"color:green;\">featuresCol='features'</span>, <span style=\"color:green;\">labelCol='label'</span>, predictionCol='prediction', probabilityCol='probability', rawPredictionCol='rawPrediction', maxDepth=5, maxBins=32, minInstancesPerNode=1, minInfoGain=0.0, maxMemoryInMB=256, cacheNodeIds=False, checkpointInterval=10, impurity='gini', <span style=\"color:green;\">numTrees=20</span>, featureSubsetStrategy='auto', <span style=\"color:darkolivegreen;\">seed=None</span>, subsamplingRate=1.0)   \n",
    "\n",
    "Se hace **fit** con los datos de **entrenamiento**. Luego las **predicciones** con los datos de **prueba**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:38:30.634406Z",
     "start_time": "2019-08-16T16:38:29.906394Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"labelIndex\",\\\n",
    "featuresCol=\"features\", numTrees=10)\n",
    "model = rf.fit(trainingData)\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:38:31.436671Z",
     "start_time": "2019-08-16T16:38:31.253635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|prediction|labelIndex|\n",
      "+----------+----------+\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"labelIndex\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:38:33.093369Z",
     "start_time": "2019-08-16T16:38:32.253657Z"
    },
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0227273\n",
      "Test Accuracy = 97.7273 %\n",
      "f1 = 0.977206\n",
      "weightedPrecision = 0.978535\n",
      "weightedRecall = 0.977273\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_3b72d38ca990) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "evaluator =\\\n",
    "MulticlassClassificationEvaluator(labelCol=\"labelIndex\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print(\"Test Accuracy = %g \" % (accuracy*100)+'%')\n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)\n",
    " \n",
    "evaluatorwp = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "wp = evaluatorwp.evaluate(predictions)\n",
    "print(\"weightedPrecision = %g\" % wp)\n",
    " \n",
    "evaluatorwr = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "wr = evaluatorwr.evaluate(predictions)\n",
    "print(\"weightedRecall = %g\" % wr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classifier\n",
    "\n",
    "**NaiveBayes**(<span style=\"color:green;\">featuresCol='features'</span>, <span style=\"color:darkolivegreen;\">labelCol='label'</span>, predictionCol='prediction', probabilityCol='probability', rawPredictionCol='rawPrediction', <span style=\"color:green;\">smoothing=1.0</span>, <span style=\"color:darkolivegreen;\">modelType='multinomial'</span>, thresholds=None, weightCol=None)   \n",
    "\n",
    "Naive Bayes soporta tanto Multinomial como Bernoulli.\n",
    "\n",
    "Nuevamente, se hace **fit** con los datos de **entrenamiento**. Luego las **predicciones** con los datos de **prueba**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:09:01.488226Z",
     "start_time": "2019-08-16T16:09:00.928973Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(labelCol=\"labelIndex\",\\\n",
    "featuresCol=\"features\", smoothing=1.0,\\\n",
    "modelType=\"multinomial\")\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:09:02.278770Z",
     "start_time": "2019-08-16T16:09:02.110069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+--------------------+----------+\n",
      "|          label|labelIndex|         probability|prediction|\n",
      "+---------------+----------+--------------------+----------+\n",
      "|    Iris-setosa|       0.0|[0.67589053383063...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.58129776152275...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.69413503465606...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.72409196648375...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.67528678942080...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.71015112065611...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.68156376940335...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.62640031158086...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.78268469801517...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.73240810290220...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.79316053353830...|       0.0|\n",
      "|    Iris-setosa|       0.0|[0.73833522522100...|       0.0|\n",
      "|Iris-versicolor|       1.0|[0.11308178808401...|       1.0|\n",
      "|Iris-versicolor|       1.0|[0.13458887007023...|       1.0|\n",
      "|Iris-versicolor|       1.0|[0.05519051774632...|       2.0|\n",
      "|Iris-versicolor|       1.0|[0.09547182390291...|       1.0|\n",
      "|Iris-versicolor|       1.0|[0.07825168440826...|       1.0|\n",
      "|Iris-versicolor|       1.0|[0.06993409404347...|       1.0|\n",
      "|Iris-versicolor|       1.0|[0.06350716945014...|       1.0|\n",
      "|Iris-versicolor|       1.0|[0.06254427356550...|       1.0|\n",
      "+---------------+----------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"label\", \"labelIndex\",\n",
    "\"probability\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-16T16:09:15.237011Z",
     "start_time": "2019-08-16T16:09:14.477028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.045454545454545414\n",
      "Test Accuracy = 95.4545 %\n",
      "f1 = 0.954545\n",
      "weightedPrecision = 0.959893\n",
      "weightedRecall = 0.954545\n",
      "NaiveBayes_e184d56042cc\n"
     ]
    }
   ],
   "source": [
    "evaluator =\\\n",
    "MulticlassClassificationEvaluator(labelCol=\"labelIndex\",\\\n",
    "predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print('Test Error = '  + str(1-accuracy))\n",
    "print(\"Test Accuracy = %g \" % (accuracy*100)+'%')\n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = evaluatorf1.evaluate(predictions)\n",
    "print(\"f1 = %g\" % f1)\n",
    " \n",
    "evaluatorwp = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "wp = evaluatorwp.evaluate(predictions)\n",
    "print(\"weightedPrecision = %g\" % wp)\n",
    " \n",
    "evaluatorwr = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "wr = evaluatorwr.evaluate(predictions)\n",
    "print(\"weightedRecall = %g\" % wr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "**MulticlassClassificationEvaluator**(predictionCol='prediction', labelCol='label', metricName='f1')   \n",
    "*metricName:* f1, weightedPrecision, weightedRecall y accuracy\n",
    "\n",
    "<u>Certeza de cada modelo:</u>\n",
    "\n",
    "- Decision Tree = <span style=\"color:green;\">97.7 %</span>\n",
    "- Random Forest = <span style=\"color:green;\">97.7 %</span>\n",
    "- Naive Bayes = <span style=\"color:red;\">95.4 %</span>\n",
    "\n",
    "<u>Precisión:</u>\n",
    "\n",
    "- Decision Tree = <span style=\"color:green;\">97.85 %</span>\n",
    "- Random Forest = <span style=\"color:green;\">97.85 %</span>\n",
    "- Naive Bayes = <span style=\"color:red;\">95.98 %</span>\n",
    "\n",
    "<u>Recall:</u>\n",
    "\n",
    "- Decision Tree = <span style=\"color:green;\">97.72 %</span>\n",
    "- Random Forest = <span style=\"color:green;\">97.72 %</span>\n",
    "- Naive Bayes = <span style=\"color:red;\">95.45 %</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
